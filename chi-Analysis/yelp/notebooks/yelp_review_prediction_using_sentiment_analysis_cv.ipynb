{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sklearn import metrics, svm, tree, ensemble, linear_model, naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_analyzed = pd.read_csv('sentiment_analysis_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_analyzed['sentiment'] = [1 if x=='positive' else 2 for x in yelp_analyzed['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open('pickels/clean_reviews','rb')  \n",
    "cleaned_reviews = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_analyzed['comment'] = cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = yelp_analyzed[['comment', 'sentiment', 'polarity', 'subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = yelp_analyzed[['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorization(train):\n",
    "    vec = feature_extraction.text.TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,5),lowercase=True)\n",
    "    train_vectors = vec.fit_transform(train)\n",
    "    return train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorization(X['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(train_vectors.toarray())\n",
    "train_X['sentiment'] = X['sentiment'].tolist()\n",
    "train_X['polarity'] = X['polarity'].tolist()\n",
    "train_X['subjectivity'] = X['subjectivity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [naive_bayes.BernoulliNB(),svm.SVC(kernel='rbf', gamma=0.58, C=0.81),tree.DecisionTreeClassifier(random_state=0),ensemble.RandomForestClassifier(criterion='entropy', n_jobs = 10),linear_model.LogisticRegression(),linear_model.SGDClassifier(),ensemble.GradientBoostingClassifier(),xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "Overall Acurracy:  0.47924209510016896 \n",
      "\n",
      "Precision of 1 class: 0.405792\n",
      "Recall of 1 class: 0.636554\n",
      "F1-Score of 1 class: 0.495629 \n",
      "\n",
      "Precision of 2 class: 0.339493\n",
      "Recall of 2 class: 0.306796\n",
      "F1-Score of 2 class: 0.322317 \n",
      "\n",
      "Precision of 3 class: 0.407157\n",
      "Recall of 3 class: 0.380362\n",
      "F1-Score of 3 class: 0.393304 \n",
      "\n",
      "Precision of 4 class: 0.529356\n",
      "Recall of 4 class: 0.452318\n",
      "F1-Score of 4 class: 0.487814 \n",
      "\n",
      "Precision of 5 class: 0.543682\n",
      "Recall of 5 class: 0.600776\n",
      "F1-Score of 5 class: 0.570805 \n",
      "\n",
      "SVC(C=0.81, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.58, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Overall Acurracy:  0.5160913991471558 \n",
      "\n",
      "Precision of 1 class: 0.559579\n",
      "Recall of 1 class: 0.500261\n",
      "F1-Score of 1 class: 0.528260 \n",
      "\n",
      "Precision of 2 class: 0.408288\n",
      "Recall of 2 class: 0.233398\n",
      "F1-Score of 2 class: 0.297010 \n",
      "\n",
      "Precision of 3 class: 0.446071\n",
      "Recall of 3 class: 0.294786\n",
      "F1-Score of 3 class: 0.354982 \n",
      "\n",
      "Precision of 4 class: 0.485201\n",
      "Recall of 4 class: 0.703040\n",
      "F1-Score of 4 class: 0.574153 \n",
      "\n",
      "Precision of 5 class: 0.631421\n",
      "Recall of 5 class: 0.543887\n",
      "F1-Score of 5 class: 0.584395 \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "\n",
      "Overall Acurracy:  0.37396411617990183 \n",
      "\n",
      "Precision of 1 class: 0.356354\n",
      "Recall of 1 class: 0.336815\n",
      "F1-Score of 1 class: 0.346309 \n",
      "\n",
      "Precision of 2 class: 0.217143\n",
      "Recall of 2 class: 0.191845\n",
      "F1-Score of 2 class: 0.203711 \n",
      "\n",
      "Precision of 3 class: 0.284278\n",
      "Recall of 3 class: 0.279437\n",
      "F1-Score of 3 class: 0.281836 \n",
      "\n",
      "Precision of 4 class: 0.417689\n",
      "Recall of 4 class: 0.432898\n",
      "F1-Score of 4 class: 0.425158 \n",
      "\n",
      "Precision of 5 class: 0.432277\n",
      "Recall of 5 class: 0.442896\n",
      "F1-Score of 5 class: 0.437522 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=10,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.4300024137098721 \n",
      "\n",
      "Precision of 1 class: 0.438039\n",
      "Recall of 1 class: 0.424543\n",
      "F1-Score of 1 class: 0.431185 \n",
      "\n",
      "Precision of 2 class: 0.308883\n",
      "Recall of 2 class: 0.178252\n",
      "F1-Score of 2 class: 0.226053 \n",
      "\n",
      "Precision of 3 class: 0.335526\n",
      "Recall of 3 class: 0.257359\n",
      "F1-Score of 3 class: 0.291290 \n",
      "\n",
      "Precision of 4 class: 0.429094\n",
      "Recall of 4 class: 0.583401\n",
      "F1-Score of 4 class: 0.494489 \n",
      "\n",
      "Precision of 5 class: 0.515231\n",
      "Recall of 5 class: 0.451947\n",
      "F1-Score of 5 class: 0.481518 \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.5173787110789283 \n",
      "\n",
      "Precision of 1 class: 0.575986\n",
      "Recall of 1 class: 0.518538\n",
      "F1-Score of 1 class: 0.545754 \n",
      "\n",
      "Precision of 2 class: 0.436441\n",
      "Recall of 2 class: 0.240000\n",
      "F1-Score of 2 class: 0.309697 \n",
      "\n",
      "Precision of 3 class: 0.442214\n",
      "Recall of 3 class: 0.324222\n",
      "F1-Score of 3 class: 0.374136 \n",
      "\n",
      "Precision of 4 class: 0.498595\n",
      "Recall of 4 class: 0.635649\n",
      "F1-Score of 4 class: 0.558841 \n",
      "\n",
      "Precision of 5 class: 0.584421\n",
      "Recall of 5 class: 0.604655\n",
      "F1-Score of 5 class: 0.594366 \n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.4949312092686459 \n",
      "\n",
      "Precision of 1 class: 0.493171\n",
      "Recall of 1 class: 0.509138\n",
      "F1-Score of 1 class: 0.501028 \n",
      "\n",
      "Precision of 2 class: 0.336837\n",
      "Recall of 2 class: 0.286214\n",
      "F1-Score of 2 class: 0.309469 \n",
      "\n",
      "Precision of 3 class: 0.422687\n",
      "Recall of 3 class: 0.271867\n",
      "F1-Score of 3 class: 0.330902 \n",
      "\n",
      "Precision of 4 class: 0.495780\n",
      "Recall of 4 class: 0.617848\n",
      "F1-Score of 4 class: 0.550124 \n",
      "\n",
      "Precision of 5 class: 0.576828\n",
      "Recall of 5 class: 0.567878\n",
      "F1-Score of 5 class: 0.572318 \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.48857510660551934 \n",
      "\n",
      "Precision of 1 class: 0.498326\n",
      "Recall of 1 class: 0.466319\n",
      "F1-Score of 1 class: 0.481791 \n",
      "\n",
      "Precision of 2 class: 0.415842\n",
      "Recall of 2 class: 0.212039\n",
      "F1-Score of 2 class: 0.280864 \n",
      "\n",
      "Precision of 3 class: 0.455681\n",
      "Recall of 3 class: 0.245374\n",
      "F1-Score of 3 class: 0.318983 \n",
      "\n",
      "Precision of 4 class: 0.454998\n",
      "Recall of 4 class: 0.686048\n",
      "F1-Score of 4 class: 0.547131 \n",
      "\n",
      "Precision of 5 class: 0.586207\n",
      "Recall of 5 class: 0.517742\n",
      "F1-Score of 5 class: 0.549851 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    clf.fit(train_X, Y)\n",
    "    preds = model_selection.cross_val_predict(clf, train_X, Y, cv=10)\n",
    "    accScore = metrics.accuracy_score(Y,preds)\n",
    "\n",
    "    lbl = [1,2,3,4,5]\n",
    "    precision = metrics.precision_score(Y,preds,average=None,labels=lbl)\n",
    "    recall = metrics.recall_score(Y,preds,average=None,labels=lbl)\n",
    "    f1Score = metrics.f1_score(Y,preds,average=None,labels=lbl)\n",
    "    \n",
    "    print(clf);\n",
    "    print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "\n",
    "    for i in range(len(lbl)):\n",
    "        print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
    "        print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
    "        print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
