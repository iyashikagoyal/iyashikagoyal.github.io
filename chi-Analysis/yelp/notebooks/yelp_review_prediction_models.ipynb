{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import metrics, svm, tree, ensemble, linear_model, naive_bayes\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open('pickels/X_train','rb')  \n",
    "X_train = pickle.load(fileObject)\n",
    "\n",
    "fileObject = open('pickels/y_train','rb')  \n",
    "y_train = pickle.load(fileObject)\n",
    "\n",
    "fileObject = open('pickels/X_test','rb')  \n",
    "X_test = pickle.load(fileObject)\n",
    "\n",
    "fileObject = open('pickels/y_test','rb')  \n",
    "y_test = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [naive_bayes.BernoulliNB(),svm.SVC(kernel='rbf', gamma=0.58, C=0.81),tree.DecisionTreeClassifier(random_state=0),ensemble.RandomForestClassifier(criterion='entropy', n_jobs = 10),linear_model.LogisticRegression(),linear_model.SGDClassifier(),ensemble.GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "Overall Acurracy:  0.4503218020917136 \n",
      "\n",
      "Precision of 1 class: 0.417040\n",
      "Recall of 1 class: 0.476923\n",
      "F1-Score of 1 class: 0.444976 \n",
      "\n",
      "Precision of 2 class: 0.339080\n",
      "Recall of 2 class: 0.215328\n",
      "F1-Score of 2 class: 0.263393 \n",
      "\n",
      "Precision of 3 class: 0.323741\n",
      "Recall of 3 class: 0.291892\n",
      "F1-Score of 3 class: 0.306993 \n",
      "\n",
      "Precision of 4 class: 0.469438\n",
      "Recall of 4 class: 0.453365\n",
      "F1-Score of 4 class: 0.461261 \n",
      "\n",
      "Precision of 5 class: 0.525176\n",
      "Recall of 5 class: 0.633922\n",
      "F1-Score of 5 class: 0.574448 \n",
      "\n",
      "SVC(C=0.81, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.58, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Overall Acurracy:  0.5287610619469026 \n",
      "\n",
      "Precision of 1 class: 0.576503\n",
      "Recall of 1 class: 0.541026\n",
      "F1-Score of 1 class: 0.558201 \n",
      "\n",
      "Precision of 2 class: 0.415761\n",
      "Recall of 2 class: 0.279197\n",
      "F1-Score of 2 class: 0.334061 \n",
      "\n",
      "Precision of 3 class: 0.426772\n",
      "Recall of 3 class: 0.292973\n",
      "F1-Score of 3 class: 0.347436 \n",
      "\n",
      "Precision of 4 class: 0.503903\n",
      "Recall of 4 class: 0.685950\n",
      "F1-Score of 4 class: 0.581000 \n",
      "\n",
      "Precision of 5 class: 0.641480\n",
      "Recall of 5 class: 0.587986\n",
      "F1-Score of 5 class: 0.613569 \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "\n",
      "Overall Acurracy:  0.3686645213193886 \n",
      "\n",
      "Precision of 1 class: 0.312796\n",
      "Recall of 1 class: 0.338462\n",
      "F1-Score of 1 class: 0.325123 \n",
      "\n",
      "Precision of 2 class: 0.224907\n",
      "Recall of 2 class: 0.220803\n",
      "F1-Score of 2 class: 0.222836 \n",
      "\n",
      "Precision of 3 class: 0.259978\n",
      "Recall of 3 class: 0.260541\n",
      "F1-Score of 3 class: 0.260259 \n",
      "\n",
      "Precision of 4 class: 0.419504\n",
      "Recall of 4 class: 0.429162\n",
      "F1-Score of 4 class: 0.424278 \n",
      "\n",
      "Precision of 5 class: 0.452663\n",
      "Recall of 5 class: 0.432509\n",
      "F1-Score of 5 class: 0.442356 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=10,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.41773934030571197 \n",
      "\n",
      "Precision of 1 class: 0.360000\n",
      "Recall of 1 class: 0.415385\n",
      "F1-Score of 1 class: 0.385714 \n",
      "\n",
      "Precision of 2 class: 0.297030\n",
      "Recall of 2 class: 0.218978\n",
      "F1-Score of 2 class: 0.252101 \n",
      "\n",
      "Precision of 3 class: 0.306469\n",
      "Recall of 3 class: 0.312432\n",
      "F1-Score of 3 class: 0.309422 \n",
      "\n",
      "Precision of 4 class: 0.445415\n",
      "Recall of 4 class: 0.481700\n",
      "F1-Score of 4 class: 0.462847 \n",
      "\n",
      "Precision of 5 class: 0.513775\n",
      "Recall of 5 class: 0.487633\n",
      "F1-Score of 5 class: 0.500363 \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.49617860016090104 \n",
      "\n",
      "Precision of 1 class: 0.449909\n",
      "Recall of 1 class: 0.633333\n",
      "F1-Score of 1 class: 0.526092 \n",
      "\n",
      "Precision of 2 class: 0.317965\n",
      "Recall of 2 class: 0.364964\n",
      "F1-Score of 2 class: 0.339847 \n",
      "\n",
      "Precision of 3 class: 0.385177\n",
      "Recall of 3 class: 0.398919\n",
      "F1-Score of 3 class: 0.391928 \n",
      "\n",
      "Precision of 4 class: 0.550778\n",
      "Recall of 4 class: 0.438607\n",
      "F1-Score of 4 class: 0.488334 \n",
      "\n",
      "Precision of 5 class: 0.610625\n",
      "Recall of 5 class: 0.641696\n",
      "F1-Score of 5 class: 0.625775 \n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.48652453740949314 \n",
      "\n",
      "Precision of 1 class: 0.393007\n",
      "Recall of 1 class: 0.720513\n",
      "F1-Score of 1 class: 0.508597 \n",
      "\n",
      "Precision of 2 class: 0.341202\n",
      "Recall of 2 class: 0.290146\n",
      "F1-Score of 2 class: 0.313609 \n",
      "\n",
      "Precision of 3 class: 0.376826\n",
      "Recall of 3 class: 0.418378\n",
      "F1-Score of 3 class: 0.396516 \n",
      "\n",
      "Precision of 4 class: 0.537097\n",
      "Recall of 4 class: 0.393152\n",
      "F1-Score of 4 class: 0.453988 \n",
      "\n",
      "Precision of 5 class: 0.607612\n",
      "Recall of 5 class: 0.654417\n",
      "F1-Score of 5 class: 0.630146 \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "\n",
      "Overall Acurracy:  0.4658085277554304 \n",
      "\n",
      "Precision of 1 class: 0.457778\n",
      "Recall of 1 class: 0.528205\n",
      "F1-Score of 1 class: 0.490476 \n",
      "\n",
      "Precision of 2 class: 0.348148\n",
      "Recall of 2 class: 0.257299\n",
      "F1-Score of 2 class: 0.295908 \n",
      "\n",
      "Precision of 3 class: 0.371314\n",
      "Recall of 3 class: 0.299459\n",
      "F1-Score of 3 class: 0.331538 \n",
      "\n",
      "Precision of 4 class: 0.485630\n",
      "Recall of 4 class: 0.488784\n",
      "F1-Score of 4 class: 0.487202 \n",
      "\n",
      "Precision of 5 class: 0.518607\n",
      "Recall of 5 class: 0.610601\n",
      "F1-Score of 5 class: 0.560857 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test.toarray())\n",
    "    accScore = metrics.accuracy_score(y_test,preds)\n",
    "\n",
    "    lbl = [1,2,3,4,5]\n",
    "    precision = metrics.precision_score(y_test,preds,average=None,labels=lbl)\n",
    "    recall = metrics.recall_score(y_test,preds,average=None,labels=lbl)\n",
    "    f1Score = metrics.f1_score(y_test,preds,average=None,labels=lbl)\n",
    "    \n",
    "    print(clf);\n",
    "    print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "\n",
    "    for i in range(len(lbl)):\n",
    "        print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
    "        print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
    "        print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lbl' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4998146f984e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mf1Score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lbl' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('bnb', clfs[0]), ('dt', clfs[1]), ('rf', clfs[2]),('lr',clfs[3]),('sgd',clfs[4]),('gb',clfs[5])], voting='hard')\n",
    "eclf.fit(X_train, y_train)\n",
    "preds = eclf.predict(X_test.toarray())\n",
    "accScore = metrics.accuracy_score(y_test,preds)\n",
    "labels = [1,2,3,4,5]\n",
    "\n",
    "precision = metrics.precision_score(y_test,preds,average=None,labels=labels)\n",
    "recall = metrics.recall_score(y_test,preds,average=None,labels=labels)\n",
    "f1Score = metrics.f1_score(y_test,preds,average=None,labels=labels)\n",
    "\n",
    "print(eclf)\n",
    "print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print(\"Precision of %s class: %f\" %(labels[i],precision[i]))\n",
    "    print(\"Recall of %s class: %f\" %(labels[i],recall[i]))\n",
    "    print(\"F1-Score of %s class: %f\" %(labels[i],f1Score[i]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('bnb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)), ('dt', SVC(C=0.81, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.58, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  to...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n",
      "\n",
      "Overall Acurracy:  0.5050281576830249 \n",
      "\n",
      "Precision of 1 class: 0.431148\n",
      "Recall of 1 class: 0.674359\n",
      "F1-Score of 1 class: 0.526000 \n",
      "\n",
      "Precision of 2 class: 0.362319\n",
      "Recall of 2 class: 0.319343\n",
      "F1-Score of 2 class: 0.339476 \n",
      "\n",
      "Precision of 3 class: 0.398551\n",
      "Recall of 3 class: 0.356757\n",
      "F1-Score of 3 class: 0.376497 \n",
      "\n",
      "Precision of 4 class: 0.521363\n",
      "Recall of 4 class: 0.533058\n",
      "F1-Score of 4 class: 0.527145 \n",
      "\n",
      "Precision of 5 class: 0.636846\n",
      "Recall of 5 class: 0.593640\n",
      "F1-Score of 5 class: 0.614484 \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test.toarray())\n",
    "accScore = metrics.accuracy_score(y_test,preds)\n",
    "labels = [1,2,3,4,5]\n",
    "\n",
    "precision = metrics.precision_score(y_test,preds,average=None,labels=labels)\n",
    "recall = metrics.recall_score(y_test,preds,average=None,labels=labels)\n",
    "f1Score = metrics.f1_score(y_test,preds,average=None,labels=labels)\n",
    "\n",
    "print(clf)\n",
    "print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print(\"Precision of %s class: %f\" %(labels[i],precision[i]))\n",
    "    print(\"Recall of %s class: %f\" %(labels[i],recall[i]))\n",
    "    print(\"F1-Score of %s class: %f\" %(labels[i],f1Score[i]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\n",
      "Overall Acurracy:  0.46218825422365245 \n",
      "\n",
      "Precision of 1 class: 0.440928\n",
      "Recall of 1 class: 0.535897\n",
      "F1-Score of 1 class: 0.483796 \n",
      "\n",
      "Precision of 2 class: 0.369509\n",
      "Recall of 2 class: 0.260949\n",
      "F1-Score of 2 class: 0.305882 \n",
      "\n",
      "Precision of 3 class: 0.384025\n",
      "Recall of 3 class: 0.270270\n",
      "F1-Score of 3 class: 0.317259 \n",
      "\n",
      "Precision of 4 class: 0.469714\n",
      "Recall of 4 class: 0.485242\n",
      "F1-Score of 4 class: 0.477352 \n",
      "\n",
      "Precision of 5 class: 0.511111\n",
      "Recall of 5 class: 0.617668\n",
      "F1-Score of 5 class: 0.559360 \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
